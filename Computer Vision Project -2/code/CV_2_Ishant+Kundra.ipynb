{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vNbfBt59OYT"
   },
   "source": [
    "# CV-2\n",
    "# ISHANT KUNDRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlCef4HapHRz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLW19fVS9Pn7"
   },
   "source": [
    "## Q1. Import and Understand the data [7 Marks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Import and read ‘images.npy’. [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jz2YiJ2gpjgB"
   },
   "outputs": [],
   "source": [
    "images_npy=np.load(\"Desktop/data/images.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrSppiUdpoll"
   },
   "outputs": [],
   "source": [
    "images = images_npy[:,0]\n",
    "mask = images_npy[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "RcRKDvH9p8o_",
    "outputId": "2085860d-f0ad-495f-820f-975552f169a2"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "JEyjtbqUqAW5",
    "outputId": "24b976f9-37df-49b3-96c6-b1a1b1d089fc"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[302])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffIH2lGUqD0A",
    "outputId": "69e0636b-c282-4fd9-af02-3a3dc6479771"
   },
   "outputs": [],
   "source": [
    "print(images[302].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_npy[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CT_xai0eqH79",
    "outputId": "33e719b8-2c5a-4e03-fbe5-772f0cd3a908"
   },
   "outputs": [],
   "source": [
    "mask[302] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhhZ-U6FqPlN"
   },
   "outputs": [],
   "source": [
    "img_w= 224\n",
    "img_h = 224\n",
    "alpha= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GTUFVxf9eiy"
   },
   "source": [
    "### B. Split the data into Features(X) & labels(Y). Unify shape of all the images. [3 Marks] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzuNK3McqSw9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "masks = np.zeros((int(images_npy.shape[0]),img_h,img_w))\n",
    "xtrain = np.zeros((int(images_npy.shape[0]),img_h,img_w,3))\n",
    "for index in range(images_npy.shape[0]):\n",
    "    image_n = images_npy[index][0]\n",
    "    image_n= cv2.resize(image_n,dsize=(img_h, img_w),interpolation=cv2.INTER_CUBIC)\n",
    "    try:\n",
    "      image_n = image_n[:, :, :3]\n",
    "    except:\n",
    "      continue\n",
    "  \n",
    "    xtrain[index] = preprocess_input(np.array(image_n))\n",
    "    for i in images_npy[index][1]:\n",
    "        x1=int(i[\"points\"][0]['x']*img_w)\n",
    "        x2=int(i[\"points\"][1]['x']*img_w)\n",
    "        y1=int(i[\"points\"][0]['y']*img_h)\n",
    "        y2=int(i[\"points\"][1]['y']*img_h)\n",
    "        masks[index][y1:y2, x1:x2]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o1ifV6i9q6E"
   },
   "source": [
    "### C. Split the data into train and test[400:9]. [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hIAF9meqo1H",
    "outputId": "caa334f0-d2f7-4012-856c-75e719b56e59"
   },
   "outputs": [],
   "source": [
    "print(xtrain.shape)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Select random image from the train data and display original image and masked image. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=images_npy[:,0]\n",
    "Y=images_npy[:,1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.022)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot random image along with its masked image\n",
    "j=np.random.randint(0,399)\n",
    "for index in range(X_train.shape[0]):\n",
    "    img = images_npy[index][0]\n",
    "    img = cv2.resize(img, dsize=(200, 200), interpolation=cv2.INTER_CUBIC)\n",
    "original_image=X_train[j]\n",
    "plt.imshow(original_image/255,cmap=plt.cm.binary)\n",
    "def detect_mask():\n",
    "  face_cascade = cv2.CascadeClassifier('Desktop/data/haarcascade_frontalface_default.xml')\n",
    "  global j\n",
    "  \n",
    "  \n",
    "  #get the cordinates for the human face mask\n",
    "  \n",
    "  face_rects = face_cascade.detectMultiScale(X_train[j]) \n",
    "    \n",
    "  for (x,y,w,h) in face_rects: \n",
    "      cv2.rectangle(X_train[j], (x,y), (x+w,y+h), (255,255,255), 5)\n",
    "      plt.imshow(X_train[j])\n",
    "      \n",
    "detect_mask() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "U-jlxgBdMI20",
    "outputId": "9381ebf3-1229-4852-b4b6-1b79cfb16b46"
   },
   "outputs": [],
   "source": [
    "plt.imshow(xtrain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyZst49e-Yg4"
   },
   "source": [
    "## Q2. Model building [11 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Design a face mask detection model. [4 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0zvcbFBq8ob"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Concatenate, UpSampling2D, Conv2D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "height_c= 28\n",
    "width_c= 28\n",
    "batch= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_U6kWEIrMDT",
    "outputId": "08308c15-f2bb-4c68-e457-9024f1157e92"
   },
   "outputs": [],
   "source": [
    "mobilenet = MobileNet(input_shape=(img_h,img_w,3), include_top=False, alpha=alpha, weights=\"imagenet\")\n",
    "mobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGiEj3SqrPMb"
   },
   "outputs": [],
   "source": [
    "def create_model(trainable=False):\n",
    "    mobilenet = MobileNet(input_shape=(img_h,img_w,3), include_top=False, alpha=alpha, weights=\"imagenet\")\n",
    "\n",
    "    for layer in mobilenet.layers:\n",
    "        layer.trainable = trainable\n",
    "        \n",
    "    block0= mobilenet.layers[0].input\n",
    "    block1 =mobilenet.get_layer(\"conv_pw_1_relu\").output\n",
    "    block2 =mobilenet.get_layer(\"conv_pw_2_relu\").output\n",
    "    block3 =mobilenet.get_layer(\"conv_pw_3_relu\").output\n",
    "    block5 =mobilenet.get_layer(\"conv_pw_5_relu\").output\n",
    "    block11 =mobilenet.get_layer(\"conv_pw_11_relu\").output\n",
    "    block13 =mobilenet.get_layer(\"conv_pw_13_relu\").output\n",
    "\n",
    "\n",
    "    dB= Concatenate()([UpSampling2D()(block13), block11])\n",
    "    dB= Concatenate()([UpSampling2D()(dB), block5])\n",
    "    dB= Concatenate()([UpSampling2D()(dB), block3])\n",
    "    dB= Concatenate()([UpSampling2D()(dB), block1])\n",
    "    dB= Concatenate()([UpSampling2D()(dB), block0])\n",
    "\n",
    "    dB= Conv2D(1, kernel_size=1, activation=\"sigmoid\")(dB)\n",
    "    dB= Reshape((img_h,img_w))(dB)\n",
    "\n",
    "    return Model(inputs=mobilenet.input, outputs=dB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnmeTzkHr0_y",
    "outputId": "077c9fd5-8905-4153-8adb-4a3c5bb47709"
   },
   "outputs": [],
   "source": [
    "mobilenet=create_model()\n",
    "mobilenet.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2Yw-Q_t_98U"
   },
   "source": [
    "### B. Design your own Dice Coefficient and Loss function. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lXe8tqnr6tf"
   },
   "outputs": [],
   "source": [
    "def dice_coff(y_true, y_pred):\n",
    "    num = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denom = tf.reduce_sum(y_true + y_pred)\n",
    "\n",
    "    return num / (denom + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CcLaIk1AH6Q"
   },
   "source": [
    "### C. Train and tune the model as required. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntYePev1ueaP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.backend import log, epsilon\n",
    "def loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - log(dice_coff(y_true, y_pred) + epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMgqRkSGuiO4",
    "outputId": "a9f4241a-b003-4d4e-9053-356051261325"
   },
   "outputs": [],
   "source": [
    "model = create_model(False)\n",
    "model.summary()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=loss, optimizer = optimizer, metrics=[dice_coff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axWL3XNouszy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"min\", save_freq=1)\n",
    "stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=1, min_lr=1e-6, verbose=1, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stnYlTY0u5eU",
    "outputId": "41acee33-add1-4188-eea4-1e51b92f3b95"
   },
   "outputs": [],
   "source": [
    "model.fit(xtrain,masks,epochs = 1,verbose=1,batch_size=3,callbacks=[checkpoint,reduce_lr,stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Evaluate and share insights on performance of the model. [2 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Mobilenet\n",
    "Build with 992 training images of \n",
    "\n",
    "\n",
    "\n",
    "Parameters for evalution \n",
    "\n",
    "Loss--- During traing, loss perfromance is getting improved, from around 3.4 to 1.08.\n",
    "The early stopping save from stucking into local minima.\n",
    "Dice coefficient is also improving ( from 0.14 to 0.33), which will improve the pixel-wise prediction efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "IhlhUqdru9Qy",
    "outputId": "ef6aaea6-1682-495a-bc45-7c37b887be4b"
   },
   "outputs": [],
   "source": [
    "image_test=images_npy[400][0]\n",
    "plt.imshow(image_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = image_test\n",
    "image = cv2.resize(sample_image, dsize=(img_h,img_w), interpolation=cv2.INTER_CUBIC)\n",
    "feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "pred_mask = cv2.resize(1.0*(model.predict(x=np.array([feat_scaled]))[0] > 0.2), (img_w,img_h))\n",
    "\n",
    "image2 = image\n",
    "image2[:,:,0] = pred_mask*image[:,:,0]\n",
    "image2[:,:,1] = pred_mask*image[:,:,1]\n",
    "image2[:,:,2] = pred_mask*image[:,:,2]\n",
    "\n",
    "out_image = image2\n",
    "\n",
    "plt.imshow(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_mask, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KXmRMeZBLlE"
   },
   "source": [
    "## Q3. Test the model predictions on the test image: ‘image with index 3 in the test data’ and visualise the predicted masks on the faces in the image. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "YTZs9WBDv1GI",
    "outputId": "240c54b9-4a8e-4660-8d07-e1c505796248"
   },
   "outputs": [],
   "source": [
    "sample_image = image_test\n",
    "image = cv2.resize(sample_image, dsize=(img_h,img_w), interpolation=cv2.INTER_CUBIC)\n",
    "feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "pred_mask = cv2.resize(1.0*(model.predict(x=np.array([feat_scaled]))[0] > 0.2), (img_w,img_h))\n",
    "\n",
    "image2 = image\n",
    "image2[:,:,0] = pred_mask*image[:,:,0]\n",
    "image2[:,:,1] = pred_mask*image[:,:,1]\n",
    "image2[:,:,2] = pred_mask*image[:,:,2]\n",
    "\n",
    "out_image = image2\n",
    "\n",
    "plt.imshow(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "O15i3qc1ebXo",
    "outputId": "79de069d-088f-4e07-c64f-d428884b51c5"
   },
   "outputs": [],
   "source": [
    "plt.imshow(pred_mask, alpha=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GopXBUPzel0g"
   },
   "source": [
    "=============== PART B  ======================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4F8jpmOv7NH"
   },
   "source": [
    "### Create an image dataset to be used by AI team build an image classifier data. \n",
    "\n",
    "### Profile images of people are given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSxzAj9ewKaW"
   },
   "source": [
    "## Q1. Read/import images from folder ‘training_images’. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQMCWfC2v-f8"
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHAf-BQa6Oy7"
   },
   "source": [
    "## Q2. Write a loop which will iterate through all the images in the ‘training_images’ folder and detect the faces present on all the images. [3 Marks]\n",
    "\n",
    "\n",
    "## Q3. From the same loop above, extract metadata of the faces and write into a DataFrame. [3 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Save the output Dataframe in .csv format. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qrfy6TS6D_6f"
   },
   "outputs": [],
   "source": [
    "def mask_csv(path):\n",
    "    import os\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "        \n",
    "    face=cv2.CascadeClassifier(\"Desktop/data/haarcascade_frontalface_default.xml\")\n",
    "    li = os.listdir(path)\n",
    "    name_of_img = []\n",
    "    no_of_img = []\n",
    "    x=[]\n",
    "    y=[]\n",
    "    h=[]\n",
    "    w=[]\n",
    "\n",
    "    for i in range(len(li)):    \n",
    "        img = cv2.imread(path+li[i])\n",
    "#         img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect the number of face and quardinates\n",
    "        \n",
    "        find_faces = face.detectMultiScale(img,1.1,20)\n",
    "        for (x1,y1,w1,h1) in find_faces:\n",
    "            \n",
    "            \n",
    "            name_of_img.append(li[i])\n",
    "            no_of_img.append(len(find_faces))\n",
    "            \n",
    "            x.append(x1)\n",
    "            y.append(y1)\n",
    "            w.append(w1)\n",
    "            h.append(h1)\n",
    "            \n",
    "            img1 = cv2.rectangle(img,(x1,y1),(x1+w1,y1+h1),(127,0,205),3)\n",
    "            img1= cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        plt.matshow(img1)       \n",
    "        \n",
    "    data_dict = {'x':x,'y':y, 'w':w,'h':h,'no_of_img':no_of_img,'name_of_img':name_of_img}\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    df.to_csv('test.csv')\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9pYE0mSwc7oL",
    "outputId": "7fb9d08d-b2fb-4061-ae24-47e3792c4801"
   },
   "outputs": [],
   "source": [
    "mask_csv(\"Desktop/data/training_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============== PART C  ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Unzip, read and Load data(‘PINS.zip’) into session. [2 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Write function to create metadata of the image. [4 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Write a loop to iterate through each and every image and create metadata for all the images. [4 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class IdentityMetadata():\n",
    "    def __init__(self, base, name, file):\n",
    "       \n",
    "        self.base = base\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.file = file\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.image_path()\n",
    "\n",
    "    def image_path(self):\n",
    "        return os.path.join(self.base, self.name, self.file) \n",
    "    \n",
    "def load_metadata(path):\n",
    "    metadata = []\n",
    "    for i in os.listdir(path):\n",
    "        for f in os.listdir(os.path.join(path, i)):\n",
    "           \n",
    "            ext = os.path.splitext(f)[1]\n",
    "            if ext == '.jpg' or ext == '.jpeg':\n",
    "                metadata.append(IdentityMetadata(path, i, f))\n",
    "    return np.array(metadata)\n",
    "metadata = load_metadata('Desktop/data/PINS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Activation\n",
    "\n",
    "def vgg_face():\t\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "    \n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=vgg_face()\n",
    "model.load_weights('Desktop/data/vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vgg_face_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_face_descriptor.inputs, vgg_face_descriptor.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Generate Embeddings vectors on the each face in the dataset. [4 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Build distance metrics for identifying the distance between two similar and dissimilar images. [4 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    return img[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((metadata.shape[0], 2622))\n",
    "for i, m in enumerate(metadata):\n",
    "    img_path = metadata[i].image_path()\n",
    "    img = load_image(img_path)\n",
    "    img = (img / 255.).astype(np.float32)\n",
    "    img = cv2.resize(img, dsize = (224,224))\n",
    "    embedding_vector = vgg_face_descriptor.predict(np.expand_dims(img, axis=0))[0]\n",
    "    embeddings[i]=embedding_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[1][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(emb1, emb2):\n",
    "    return np.sum(np.square(emb1 - emb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_pair(idx1, idx2):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.suptitle(f'Distance between {idx1} & {idx2}= {distance(embeddings[idx1], embeddings[idx2]):.2f}')\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(load_image(metadata[idx1].image_path()))\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(load_image(metadata[idx2].image_path()));    \n",
    "\n",
    "show_pair(40, 41)\n",
    "show_pair(20, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.arange(metadata.shape[0]) % 9 != 0     \n",
    "test_idx = np.arange(metadata.shape[0]) % 9 == 0\n",
    "\n",
    "\n",
    "X_train = embeddings[train_idx]\n",
    "\n",
    "\n",
    "X_test = embeddings[test_idx]\n",
    "targets = np.array([m.name for m in metadata])\n",
    "\n",
    "\n",
    "y_train = targets[train_idx]\n",
    "\n",
    "\n",
    "y_test = targets[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0], y_train[72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_test)), len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le.classes_)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Use PCA for dimensionality reduction. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=128)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Build an SVM classifier in order to map each image to its right person. [4 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=5., gamma=0.001)\n",
    "clf.fit(X_train_pca, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_encoded = le.inverse_transform(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded[32:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve,accuracy_score,f1_score,precision_score,recall_score\n",
    "accuracy_score(y_test_encoded, y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. Import and display the the test images. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = metadata[11].image_path()\n",
    "img = load_image(\"Desktop/data/Benedict_Cumberbatch9.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = metadata[0].image_path()\n",
    "img2= load_image(\"Desktop/data/Dwayne_Johnson4.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Rock=\"Desktop/data/PINS1/PINS1/PINS1/pins_Dwayne_Johnson/Dwayne_Johnson4.jpg\"\n",
    "for i in range(len(metadata)):\n",
    "  if str(metadata[i])==\"Desktop/data/Dwayne_Johnson4.jpg\":\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(load_image(metadata[580].image_path()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_DrStrange=\"Desktop/data/PINS1/PINS1/PINS1/pins_Benedict_Cumberbatch/Benedict_Cumberbatch9.jpg\"\n",
    "for i in range(len(metadata)):\n",
    "  if str(metadata[i])==\"Desktop/data/PINS1/PINS1/PINS1/pins_Benedict_Cumberbatch/Benedict_Cumberbatch9.jpg\":\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(load_image(metadata[1052].image_path()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. Use the trained SVM model to predict the face on both test images. [4 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Image DrStrange\n",
    "test_idx =580\n",
    "\n",
    "test_image = load_image(metadata[test_idx].image_path())\n",
    "test_prediction = y_predict[test_idx]\n",
    "test_identity =  y_predict_encoded[test_idx]\n",
    "\n",
    "plt.imshow(test_image)\n",
    "plt.title(f\"Celebrity's name is {test_identity}\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Image Rock\n",
    "test_idx =1052\n",
    "\n",
    "test_image = load_image(metadata[test_idx].image_path())\n",
    "test_prediction = y_predict[test_idx]\n",
    "test_identity =  y_predict_encoded[test_idx]\n",
    "\n",
    "plt.imshow(test_image)\n",
    "plt.title(f\"Celebrity's name is {test_identity}\");"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
